{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Audio and Image Processing\n",
    "\n",
    "You were introduced to Jupyter notebooks in the previous section. We will continue to use notebooks.\n",
    "\n",
    "This lab is an introduction to audio and image processing. You will be learning how to use some Python packages that are commonly used in these domains. Part 1 deals will audio, and part 2 will be on images. There are 6 exercises in total. Make sure you attempt all of them.\n",
    "\n",
    "Name: \n",
    "\n",
    "NetID:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Necessary packages\n",
    "\n",
    "- scipy\n",
    "- matplotlib\n",
    "- numpy\n",
    "- IPython\n",
    "\n",
    "If you are using Canopy or Anaconda, you wouldn't need any additional packages for this lab. If needed, you can install packages using `pip install` or `conda install` depending on your environment.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the relevant libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from __future__ import print_function\n",
    "from scipy.io import wavfile\n",
    "from matplotlib import pyplot as plt\n",
    "from IPython.display import Audio\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1 - Audio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sound is very small pressure changes in the medium it it travelling in, this pressure change is measured by a microphone and converted into signal levels. The most direct way to visualize this captured information is to plot out these values directly:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Load the wav file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_file = 'data/italian.wav'\n",
    "Fs, wav = wavfile.read(audio_file)\n",
    "\n",
    "print('Length of audio signal: ' + str(wav.shape))\n",
    "print(type(wav))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Listen to the the audio "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Audio(audio_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Plot the audio signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(16,5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(wav);\n",
    "plt.title('Italian speech')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:blue\">Exercise 1</span>\n",
    "#### 1. Write a function to compute the length of the audio file in seconds\n",
    "#### 2. Write a function to plot out a short section of the audio clip instead of the whole length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Solution \n",
    "\n",
    "def audioLength(signal, sampling_rate):\n",
    "    '''\n",
    "        Given an input signal and sampling rate, \n",
    "        compute the length of the audio file\n",
    "        \n",
    "        Args:\n",
    "            signal: [ndarray] samples/single channel of audio file\n",
    "            sampling_rate: [float] the sampling rate Fs of the signal\n",
    "        Returns:\n",
    "            duration: [float] value of the duration in seconds\n",
    "        Hint: \n",
    "            Refer to the documentation of read() in scipy.io.wavefile\n",
    "    '''        \n",
    "    \n",
    "    duration = \n",
    "    return duration\n",
    "\n",
    "def getWindow(signal, start, end, window_func=None):\n",
    "    '''\n",
    "        Given an input signal, extract a windowFunc-windowed \n",
    "        part of the signal from start to end times\n",
    "        \n",
    "        Args:\n",
    "            signal: [ndarray] audio signal \n",
    "            start: [int] start index\n",
    "            end: [int] end index\n",
    "            window_func: [string] method to window the signal\n",
    "        Returns:\n",
    "            section: [ndarray] signal values from [start, end)\n",
    "        Remark:\n",
    "            1. Make sure to divide the selected section by its length \n",
    "               for normalization.\n",
    "    '''\n",
    "\n",
    "    if window_func == None:\n",
    "        section = \n",
    "    return section"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use the above functions to visualize the sound clip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Time length of audio file (in sec)' , audioLength(wav, Fs))\n",
    "plt.figure()\n",
    "plt.title('Plot of a section of the audio signal')\n",
    "plt.plot(getWindow(wav, 100000, 200000))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Better Visualization\n",
    "\n",
    "It is difficult to see what's happening in the audio signal from the plots above. To analyze audio content, in applications such as speaker recognition or audio content identification, a necessary tool is the **spectrogram**. The spectrogram can be used to visualize the frequency content of the audio signal as it progresses over time.\n",
    "\n",
    "Mathematically, the spectrogram is the **squared-magnitude** of \n",
    "the Fourier transform of overlapping segments, or windows, of the audio signal.\n",
    "To generate the spectrogram, the signal must first be separated into\n",
    "overlapping segments. If we denote the signal as \n",
    "$\\vec{x} = [x_{0}, x_{1},..., x_{N-1}]$, a one-dimensional vector of $N$ samples,\n",
    "Then the segments would be given as\n",
    "$$ \n",
    "\\vec{x}_{0}=[x_{0}, x_{1},..., x_{N}],\\\\\n",
    "\\vec{x}_{1}=[x_{M}, x_{M+1},..., x_{M+N}],\\\\\n",
    "\\vdots\\\\\n",
    "\\vec{x}_{i}=[x_{iM}, x_{iM + 1},..., x_{iM+N}],\n",
    "$$\n",
    "where $M$ is the step size between windows\n",
    "and $N$ is the length of each window. To generate a smoother spectrogram,\n",
    "it is common to multiply the windows element-wise with a \n",
    "*windowing filter* $\\vec{w}$. A popular choice of a window\n",
    "filter is the Hamming window."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Windowing Functions\n",
    "\n",
    "Using hard cut-offs at the boundaries of the windows can cause various undesirable artifacts. In order to reduce these effects, windowing functions can be applied to these rectangular clips. Numpy provides `hamming()` to generate what is known as the Hamming window. We apply this window to the signal we obtained above by performing an elementwise multiplication.\n",
    "\n",
    "Note: Not multiplying the signal by any fancy windowing function is called the rectangular window."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualizing the hamming window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 200000 - 100000\n",
    "w = np.hamming(N)      # generate a Hamming window of length N\n",
    "s = wav[100000:200000] # how many samples does s have? N or N+1?\n",
    "\n",
    "fig = plt.figure()  # create a figure object\n",
    "ax = fig.add_subplot(1, 1, 1)  # create an axes object in the figure\n",
    "ax.plot(w) # plot the window\n",
    "ax.set_title('Hamming Window')\n",
    "ax.set_xlabel('time (samples)')\n",
    "ax.set_ylabel('amplitude')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:blue\">Exercise 2</span>\n",
    "\n",
    "Now modify the definition of your `getWindow()` function, it should now apply the *hamming* window to the signal that was obtained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Solution \n",
    "\n",
    "def getWindow(signal, start, end, window_func=None):\n",
    "    '''\n",
    "        Given an input signal, extract a windowFunc-windowed \n",
    "        part of the signal from start to end times\n",
    "        \n",
    "        Args:\n",
    "            signal: [ndarray] audio signal \n",
    "            start: [int] start index\n",
    "            end: [int] end index\n",
    "            window_func: [string] method to window the signal\n",
    "        Returns:\n",
    "            section: [ndarray] signal values from [start, end)\n",
    "        Hint:\n",
    "            1. Generate a hamming window with the correct length\n",
    "            2. Multiply your signal section with the hamming window\n",
    "            3. Make sure to normalize the Hamming window to sum to 1\n",
    "    '''\n",
    "    if window_func == None:\n",
    "        section =\n",
    "    elif window_func == 'hamming':\n",
    "        section = \n",
    "    else: \n",
    "        pass\n",
    "    return section"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize the windowed signal and compare with the original section (rectangular window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12, 5))  # create a figure object\n",
    "\n",
    "ax = fig.add_subplot(1, 2, 1)  # create an axes object in the figure\n",
    "ax.plot(getWindow(wav, 100000, 200000))\n",
    "ax.set_title('Rectangular Window')\n",
    "ax.set_xlabel('Time (samples)')\n",
    "ax.set_ylabel('Amplitude')\n",
    "\n",
    "ax = fig.add_subplot(1, 2, 2)  # create an axes object in the figure\n",
    "plt.plot(getWindow(wav, 100000, 200000, window_func='hamming'))\n",
    "ax.set_title('Hamming Window')\n",
    "ax.set_xlabel('Time (samples)')\n",
    "ax.set_ylabel('Amplitude')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comment on the differences observed for the two windows above\n",
    "\n",
    "#### Your answer here:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fourier Transform\n",
    "\n",
    "Applying a Fourier Transform to a signal allows us to view it's frequency content.\n",
    "\n",
    "To generate the frequency content for the spectrogram, the **Fourier transform** is applied\n",
    "to the windowed segments of the input and the magnitude of the result is squared\n",
    "and stored,\n",
    "\n",
    "$$\\vec{f}_{i} = \\left\\|\\mathcal{FFT}\\left(\\vec{w}\\odot \\vec{x}_{i}\\right)\\right\\|^{2},$$\n",
    "\n",
    "where $\\odot$ represents elementwise multiplication. Note that the Fourier transform\n",
    "produces both negative and positive frequencies, but the content of the negative frequencies are\n",
    "redundant, since the spectrogram stores the *magnitude* of the FT result and we are dealing\n",
    "with *real* signals. Therefore, only $\\vec{f}_{i,[0:N/2 + 1]}$ is needed. The function **rfft()** takes\n",
    "care of this for you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_of_s = np.fft.rfft(wav)                   # Fourier transform of signal, keeping only the positive frequencies\n",
    "freq = np.arange(f_of_s.size)*(Fs/2.)/f_of_s.size    # generate frequencies for plot\n",
    "\n",
    "fig_fft = plt.figure()\n",
    "ax = fig_fft.add_subplot(1, 1, 1)  # create an axes object in the figure\n",
    "ax.plot(freq, np.absolute(f_of_s))\n",
    "ax.set_title('Magnitude of Fourier Transform of Signal')\n",
    "ax.set_xlabel('Frequency (Hz)')\n",
    "ax.set_ylabel('Magnitude')\n",
    "ax.set_xlim(0,22050)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Is the trend of rapid decay something you expected to see? Why?\n",
    "\n",
    "#### Your answer here:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:blue\">Exercise 3</span>\n",
    "\n",
    "#### There are 3 subparts in this exercise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (a) Plot only the initial parts of the Fourier Transform and notice the spectrum pattern."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Solution \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (b) Plot the *frequency* content of a\n",
    "           1. rectangular window\n",
    "           2. Hamming window\n",
    "#### and give a brief description of the differences between these windows.\n",
    "\n",
    "Tip: Be sure to normalize the windows so that they sum to 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Solution \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (c) Plot the *frequency* content of the signal using a\n",
    "           1. rectangular window\n",
    "           2. Hamming window.\n",
    "#### by making use of the function getWindow defined previously. You might want to play with the scales on the axis to see better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Solution \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:blue\">Exercise 4</span> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Frequency Domain Visualization\n",
    "\n",
    "Here we will utilize a built in function in matplotlib to plot the spectrogram of the audio signal. The spectrogram is computed from a overlapping sliding window of the audio signal, with the windowing function applied. This is typically called the Short Time Fourier Transform(STFT) of the audio signal. Each column in the plot represents a window of the signal, the y-axis represents the frequency and the color represents the magnitude."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig, (ax1) = plt.subplots(ncols=1) # create plot\n",
    "fig.set_size_inches(15, 5)\n",
    "\n",
    "N=1024\n",
    "M=128\n",
    "\n",
    "wav_segment = wav[240000:411000]\n",
    "\n",
    "# generate & plot spectrogram (built-in function)\n",
    "data, freqs, bins, im = ax1.specgram(wav_segment,Fs = Fs, NFFT=N, noverlap=(N-M), window = np.hamming(N), cmap = 'jet')   \n",
    "ax1.axis('tight')\n",
    "ax1.set_title('Spectrogram of Channel 0')\n",
    "ax1.set_ylabel('frequency (normalized)')\n",
    "ax1.set_xlabel('time (in samples)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Your Task:\n",
    "Looking at the spectrograms above, are you able to guess the number of phrases/sentences in this speech? Describe briefly the reasons. (Feel free to verify your answer by listening to the provided wav file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution \n",
    "Your answer here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Audio(wav_segment, rate=Fs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2 - Digital Images\n",
    "\n",
    "In this part, we will be looking at digital image representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the image file and convert it into a numpy array\n",
    "img = np.array(plt.imread('data/bird.jpg'))\n",
    "img2 = np.array(plt.imread('data/bird2.jpg'))\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(img)\n",
    "plt.figure()\n",
    "plt.imshow(img2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:blue\">Exercise 5</span> \n",
    "\n",
    "Write code to do the following: \n",
    "\n",
    "1. Print the height and width of the image in pixels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Solution "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "2. Estimate the compression ratio of this JPEG image. \n",
    "    - Recall that an image is made of pixels and each pixel is about 3 bytes.\n",
    "    - Estimate the size based on the height and width of the image\n",
    "    - Obtain the actual size of the file from the system, or by using the *os* library\n",
    "    - Obtain the compression ratio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Solution \n",
    "\n",
    "expected_size = \n",
    "print('Expected size', expected_size)\n",
    "\n",
    "real_size = os.path.getsize('data/bird.jpg')\n",
    "print('Real size', real_size)\n",
    "\n",
    "compression_ratio = \n",
    "print('Compression ratio', compression_ratio)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Show the R, G, B channels seperately in a row\n",
    "    - You can picking the different colors by picking different indices of the depth axis (using `img[:, :, 0]` for example).\n",
    "    - In what order are the channels ordered along the depth dimension - R-G-B or B-G-R? Justify.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Solution \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Order for JPG image: [Your answer here]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Plot the histogram of each channel. \n",
    "    - You can use the `plt.hist()` function\n",
    "    - Are the color well-balanced in this image? Contrast to the `bird2.jpg` file.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Solution \n",
    "\n",
    "plt.figure(figsize=(12,5))\n",
    "plt.title('Parrot')\n",
    "plt.subplot(1,3,1)\n",
    "..........\n",
    "........\n",
    ".......\n",
    "....\n",
    "\n",
    "#### Solution \n",
    "plt.figure(figsize=(12,5))\n",
    "plt.title('Warbler')\n",
    "..........\n",
    "........\n",
    ".......\n",
    "....\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your comments: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Take photos of a common daily object near you, in two different settings: indoors and outdoors. Plot the R, G, B channels and the histogram of each channel for both the images and comment on any differences you note. You will use these two photos in the later labs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:blue\">Exercise 6</span> \n",
    "\n",
    "1. Do you think that the tiles A and B are of different shades/intensities in the checkerboard below?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = np.array(plt.imread('data/illusion.jpg'))\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your answer:\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Plot the intensity variation of the pixels along one vertical line. \n",
    "    - Pick an index in close to index 300 along the horizontal axis\n",
    "    - Identify the regions corresponding to tile A and tile B.\n",
    "    - Does the computer see different shades? Justify."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your answers here:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
